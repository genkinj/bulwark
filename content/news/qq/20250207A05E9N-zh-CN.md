---
title: "DeepSeek砸开裂缝，国产算力奔涌而出 | 万有AI力"
date: "2025-02-07 15:19:08"
summary: "DeepSeek是国产算力企业在春节看到的最大烟花。 2025年春节前，DeepSeek发布大模型；..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/OIt6CCE55-eZlWhJ_Vt9PQNgHlUVxT7Mnlwhiq1BEdqq8AA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

![图片](https://inews.gtimg.com/om_bt/OgMyhXkoC4pIZZVmI4hrl-FIBjYhNa9cG3P24TS8GzIaAAA/641)

DeepSeek是国产算力企业在春节看到的最大烟花。

2025年春节前，DeepSeek发布大模型；春节期间，国内GPU企业以及云计算厂商等，纷纷披露适配DeepSeek模型的进展。为此，不少科技从业人员度过了一个无休的假期。DeepSeek大模型的训练是基于英伟达的GPU，目前后者是全球大模型的算力底座（占比九成以上）。不过，DeepSeek也指向重大转变的可能：训练一款性能优异的大模型，不需要那么多高的算力投入。

DeepSeek震荡科技圈，国产算力搭配国产大模型的机会出现。沐曦CTO杨建认为，今年年底部分大模型的预训练可能会转入非英伟达的卡，明年这种趋势会更加明显。“中国市场会慢慢演变，届时英伟达会是一部分算力底座，其他国产芯片是另一部分算力底座。全球算力供应变成两条并行的线路了。”

![图片](https://inews.gtimg.com/om_bt/O7U9ksJjRO9snvzVdIrhzI9nRj269x7qkmBE_Etu0ksykAA/641)

**国产算力搭配国产模型**

春节前后，国产芯片密集适配DeepSeek。

2月1日，大模型云服务平台Silicon Cloud上线了DeepSeek-V3、DeepSeek-R1。Silicon Cloud背后的公司硅基流动特别强调，“在自研推理加速引擎加持下，硅基流动团队基于华为云昇腾云服务部署的DeepSeek 模型可获得持平全球高端GPU部署模型的效果。”

2月2日，Gitee AI表示在春节期间上线四个较小尺寸的DeepSeek模型,均部署在国产的沐曦曦云GPU上，面向开发者市场。

据沐曦CTO杨建向第一财经介绍，从双方协商到部署完成，整个过程不过两天时间。“模型大小决定了使用场景，比如1.5B模型可以用到手机上，7B及以上模型都可以用在云端或者私有化部署上。”

2月4日，摩尔线程宣布完成了小尺寸的DeepSeek模型在其自主设计的夸娥（KUAE）GPU集群上的部署，并表示即将开放夸娥智算集群，支持DeepSeek V3、R1模型及新一代蒸馏模型的分布式部署。

“DeepSeek V3和R1模型的部署需要集群能力。但基于DeepSeek蒸馏的小模型，不需要集群也能部署。摩尔线程基于自研全功能GPU，通过开源与自研双引擎方案，可以快速实现对DeepSeek蒸馏模型的推理服务部署。”摩尔线程AI与云计算副总裁王华书面回复第一财经时表示。

2月5日，云服务商优刻得宣布基于壁仞科技国产芯片的内存架构、多模型适配能力，开展包括R1在内的DeepSeek全系列模型适配工作。壁仞科技是一家中国GPU厂商。实际上，在壁仞科技的芯片上部署DeepSeek之前，优刻得已经在英伟达芯片上部署了这款大热的模型。

“我们应该是在除夕那天完成的部署。”优刻得计算产品中心研发总监王晓慧对第一财经表示，很多科技企业和技术人员被DeepSeek年前所放的大烟花所震动，度过了一个无休的春节。

在DeepSeek-V3/R1上线不久，昆仑芯也完成了全版本模型适配，其中包括DeepSeek MoE 模型及其蒸馏的Llama/Qwen等小模型。昆仑芯方面表示，该公司的P800仅需32台即可支持模型全参训练，完成模型持续训练和微调。

这几家中国芯片企业表态前后，国内国际的科技大厂也先后表示已经将DeepSeek模型纳入其产业生态，这些大厂包括了国内的阿里云、百度云以及腾讯云，美国的亚马逊云科技、Meta、谷歌等。

不过，这些科技大厂的算力底座基本都是英伟达。

“在大模型训练过程中，我认为全球98%的训练是基于英伟达GPU算力底座的。今天为止，非英伟达算力底座的训练合在一起可能也就2%的市场份额。”杨建告诉记者。

王晓慧同样认为，当下“云上算力的分布，98% 、99%都是英伟达。”

DeepSeek展示了超强的产业穿透力，不过它并没有脱离英伟达生态。王华认为，DeepSeek绕过英伟达的CUDA是误读，本质上其技术实现仍深度依赖NVIDIA生态的核心组件（PTX）。即使框架层试图抽象化CUDA API，只要底层运行在英伟达GPU上，就不可避免与CUDA工具链和硬件驱动绑定。这种依赖关系反映了当前AI算力领域“NVIDIA主导，开源生态依附”的现实格局。

![图片](https://inews.gtimg.com/om_bt/Oy-1ArxUFFlIjad6hUcKAqFaMGjYAXHhB9hKU8S-nEjFcAA/641)

**“****只是第一步跨出来了”**

“国产算力把DeepSeek模型跑起来，其实是相对比较容易的。现在大家都只是第一步跨出来了。”王晓慧表示。

国产GPU适配主流开源大模型已经有几年时间，比如支持Meta的LlaMa、阿里的通义千问等。但难点之一在于如何把模型架构跟硬件架构做比较好地结合，使其整体性能得到更大提升。

目前DeepSeek大模型搭配的国产GPU所能展示出来的性能和英伟达GPU还有一定差距。这背后原因在于DeepSeek模型本身的架构，它的训练、推理过程，最初都是在英伟达芯片上跑出来的，针对英伟达芯片做了高度的调优。“短时间内，很难把这些优化点匹配到国产芯片上来。我觉得这也是接下来各大国产芯片厂商要去做的一件事情。”

国产芯片绕过英伟达抵达最终用户，难点更在于英伟达的护城河宽且深。

“比如说他（指用户）现在跑一个（英伟达）4090或者跑一个（英伟达）H100，装一个软件报错了。他去论坛或者问身边有经验的人，就能非常容易地找到解决方案。大家遇到过类似的问题，能够在社区里面找到可以咨询的人。”杨建对记者说，而很多国产卡的信息不那么开放，社区活跃度没有那么高，用户一旦遇到卡点就很难解决，要花很多时间在非业务上。

这一点在小型团队上表现得更加明显。

直播、数字人等小型团队，有时候只有四五个人。这些团队在财力上缺乏腾挪的空间，在技术迭代上缺乏腾挪的时间。“他们做东西一定是一上来就要养活团队。哪个更容易上手，哪个钱更少，他一定是去走这条路径，而不是一上来就国产化。”王晓慧说，小型公司部署大模型的时候，优先考虑的还是英伟达的算力，这是最快看到结果，或者试错成本最低的方式。

国产芯片往往需要在价格上给出折扣，才能更好导入私有化部署的企业。王晓慧认为：“国产算力卡的性价比要达到20%、甚至30%的提升，否则企业很少有会愿意去做主动替换。”

美国在过去几年实施的高端算力芯片禁令，使得中国企业更难以获得英伟达产品，而DeepSeek爆火之后，已经有些美国企业开始炒作进一步限制中国芯片进口。美国禁令倒逼中国芯片企业发展。

“DeepSeek火了之后，美国企业是非常恐慌的。所以未来对中国算力的管控一定会越来越严。我们自身如果没有任何突破的话，算力就会成为一个瓶颈。所以国产算力是必然要去走的一条路。”王晓慧说。

![图片](https://inews.gtimg.com/om_bt/Os_ld1ZqIyiQ3WPwgb5Onz-wDy9_Hia5DqzvoZaK1z8WUAA/641)

**并行的算力供应线**

据杨建观察，DeepSeek公开的技术报告对芯片设计给出了一些建议。

“它自己在跑H800的过程中，发现有一些设计本身是不太合理的。比如芯片占用大量的算力去做通信，DeepSeek提出能不能把通信抽出来做。英伟达就很难根据这种建议去做改进，但是国产卡是有可能采纳这部分意见的。”杨建说。英伟达生态庞大而牵一发动全身，国产芯片企业普遍规模比较小，也有灵活机动的优势。“国产芯片起步没有那么早，技术栈没有那么深，想要去做一些调整，应该是比较轻量的。”

DeepSeek并不比其他国产大模型更容易搭载国产芯片。但王晓慧也认为，只要是走在这个发展路径上，一定会适配的越来越好。

王晓慧表示：“它不可能一下子把所有在英伟达上的优化，能够无缝迁移到国产卡上，这是有适配周期和过程的。但你这有了这样的一个模型架构，国产卡可以去出一些软件升级，一些还在萌芽里的芯片厂在设计上可能也会有一些新的想法，能够去让DeepSeek优化的更好。”

腾讯云、优刻得这样的平台搭载的大模型接近百款，除了使用英伟达的芯片之外，在几年前就已经适配壁仞科技等国产芯片。

最早的时候，优刻得为了能让国产卡跑起来，需要做非常多的适配、调试。但那时候的“国产卡可能跑着跑着就挂了”。

“原先我们测一些机卡，单卡的性能可能达到英伟达的一定程度。一旦到多卡多机之后，性能就明显有衰减。”王晓慧从几年前开始测试一些国产卡，她感觉进步明显，“我们去年开始已经能看到，这部分已经在缓解，有非常大的提升。”

国产算力也在日新月异地提升。

蛇年开工当天，昆仑芯新一代产品P800万卡集群点亮。昆仑芯也已适配文心系列、Llama、Qwen、ChatGLM等各类大模型的推理和训练任务；摩尔线程目前已经适配并拉起了数百个LLM模型的训练，在制造业、工程机械、教育、金融、政务、AI绘画等众多行业得到一定的应用。

杨建认为，今年年底部分大模型的预训练可能会转入非英伟达的卡，而明年这种趋势会更加明显。“到了2026年、2027年，我认为英伟达在美国仍然是最主要的预训练、甚至后训练的算力底座。但中国市场会慢慢演变，届时英伟达会是一部分算力底座，其他国产芯片是另一部分算力底座。全球算力供应变成两条并行的线路了。”

目前英伟达GPU在算力性能和生态成熟度上仍具优势，DeepSeek等大模型的技术迭代短期内难以完全脱离其生态。但长期来看，随着国产替代的推进、算法优化能力的提升，以及行业对供应链安全的重视，将逐步降低单一依赖风险。

“这一过程需要时间和技术积累，但已是不可逆的趋势。未来的算力底座更可能呈现‘多元共存’的形态，而非某一厂商的绝对主导。”王华表示。

 (本文来自第一财经)

[qq](https://new.qq.com/rain/a/20250207A05E9N00)
